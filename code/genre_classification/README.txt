Group analysis of searchlight-based cross-validated SVM genre classification
============================================================================

This analysis required the presence of several software packages:

- PyMVPA 2.4
- NiBabel 1.0 (or later)
- NiPy 0.3 (or later)
- nilearn 0.1a1
- FSL 5.8

Scripts
-------

The order of the section below reflect the order of execution within the
analysis.

mkds.py
~~~~~~~

Performs generation of input datasets for classification analysis. For each run
an HRF-modeling is performed using NiPy's GLM implementation, after spatial
smoothing of BOLD images with a Gaussian kernel of 2.0mm FWHM.

The output dataset contains one sample of beta weights per run per stimulation
category.

This script is called with a zero-based subj index and yields an output dataset
in a data/ subdirectory.

Call once per subject.


dosl.sh
~~~~~~~

Perform a searchlight analysis via PyMVPA's command line interface. Depending
on on the arguments the script will either compute a normal cross-validated SVM
searchlight, or the same on a dataset with permuted genre labels -- for
statistical analysis in the group.  The script is called with three arguments:

1. subject index (not zero-based)
2. total number of desired permutations
3. current index of permutation

Whenever the last argument is non-zero, the dataset will be permuted.

The specific analysis classification and preprocessing setup is taken from the
pymvpa2_cv_setup.py, pymvpa2_zscore_ds.py, and pymvpa2_permute.py script
snippet files.

The searchlight is configured to be of a radius of two voxels (plus the
center), and searchlight centers are spaced two voxels appart. This performs a
sparse spatial sampling with overlapping searchlight sphere. The values mapped
onto each voxel represent the mean accuracy across all classification (spheres)
a voxel was included in.

The output is one result searchlight map in the results/ subdirectory.

Call once per subject and desired searchlight map. The presented analysis used
50 permuted maps per subject.


proj4grpthresh.py
~~~~~~~~~~~~~~~~~

Script to apply the spatial transformation from individual subject space into
the space of the group BOLD template image. This script requires a functional
FSL environment.

This script is called with a zero-based subj index and yields an output dataset
in a grp_results/ subdirectory.

Call once per subject.


dogrpstats.py
~~~~~~~~~~~~~

Script to perform group statistics ala Stelzer et al. (NeuroImage 2013). This
analysis requires a large amount of CPU time and memory!

Data is merged across subjects and 100000 bootstrap samples of average
searchlight accuracy maps are generated by drawing one permutation-based map
per subject and average across subjects. Based on these samples, per-voxel
chance distributions are estimated to perform thresholding (p<0.001) of the
accuracy from the empirical (unpermuted) data.

Resulting clusters are evaluated with respect to the NULL distribution of
cluster sizes. Only clusters with a family-wise error-corrected (FDR) chance
probability of p<0.05 are reported in the results.

This script take no argument.

Four files are generated:

grpavg_stats.hdf5:            Full analysis result as a PyMVPA dataset
                              (includes various cluster statistics)
avg_acc.nii.gz:               Average group accuracy map
featurewise_thresh.nii.gz:    Voxelwise cluster-forming threshold
fwecorrected_clusters.nii.gz: Cluster map (FWE-corrected)
